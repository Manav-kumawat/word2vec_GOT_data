üêâ Word2Vec Model on Game of Thrones Dataset
This project implements a Word2Vec model trained on the Game of Thrones (GoT) text dataset to capture semantic relationships between words and characters. The model learns dense word embeddings that represent contextual meaning based on word co-occurrence within the GoT corpus.

Preprocessing using NLTK and Gensim:
Sentence tokenization using NLTK
Text cleaning, lowercasing, and stopword removal

Custom Word2Vec training:
Vector Size: 100 dimensions
Window Size: 10
Model trained using Gensim‚Äôs Word2Vec implementation

Exploratory Analysis:
Find most similar words
visualize embeddings using PCA or t-SNE

